OCR version of the Parallel Research Kernel synch_p2p
Written by David Scott
June 2016


This code implements multiple "sweeps" across an MxN 2D grid
The grid is initialized to zero except the first row and column
that are equal to max(rownum, columnnum)

The code uses the domain decomposition style of virtual "ranks" which are
a sequence of EDTs that are responsible for the same subset of data.


The grid is split into block columns across P "ranks".

The sweep starts at Array(1,1) and progresses by rows computing
Array(i,j) = Array(i-1,j) + Array(i,j-1) - Array(i-1,j-1)

After computing the first row, rank 0 should pass two numbers onto
rank 1 to allow rank 1 to start computing.  However if the
communication is expensive, it may be faster for rank 0 to
compute several rows before sending data on.  The optional input parameter
gf is this "group factor".  Note that a value of gf other than 1 is
considered "cheating" and will be marked by recording the megaflop rate
as negative

At the end of each timestep rank P-1 sends the value of Array(N-1,M-1) to rank 0 who sets
Array(0,0) = -Array(N-1,M-1) before starting the next timestep.

This makes node 0 wait for the previous timestep to finish and
also provides a way of verifying that the computation is done
correctly

All the parameters are defined inside the code:

#define T 100    //number of timesteps
#define P 10     //number of workers
#define M 1000   //global number of columns
#define N 100    //number of rows
#define GF 1     //the blocking factor

but can be overridden with run time arguments
(or just changed inside the code)



The code follows the current BKMs for OCR including:


datablocks should be created by the "rank" that uses them

"message" datablocks should be created, filled, sent, and destroyed

labeled GUIDs should be used for initialization only, being used
to send channel Events that will be used for sending/receving data

affinity hints should be used to initially distribute the ranks
among the available Policy Domains and then used to keep
all the EDTs of a rank in the same Policy Domain.

the code uses macros from macros.h "library" to simplify using
structures for all paramvs and depvs.



the code (like all OCR codes) starts in mainEdt which
creates a shared datablock and passes it to realmainEdt

realmain fills the shared datablock
creates P initEDTs and passes in the shared block and a rank
number as a parameter

(note that since it is no longer deprecated to use a datablock
you create, these two could be combined)

InitEDT creates local datablocks and passes them to p2pInitEdt

p2pInitEdt fills the private blocks, creates channelEvents,
creates the first version of p2pEdt and launches channelInitEdt

(similarly initEDT and p2pInitEDT could be combined)

channelInitEdt receives the channelEvt and stores it in the
private block.  It then launches p2pEdt

p2pEdt does the computation, sends the end data, and then clones
itself to receive the next datavalues (rank0 clones itself
at each phase although that is not required).

After finishing an iteration, rank P-1 send a single value
back to rank0 to start the next iteration.

The elapsed time of all but the first iteration is computed
using wtime().  Rank0 puts the start time in a special timer
datablock.  Rank P-1 receives the timerdatablock in the last
instantiation to record the elapsed time.


As usual the code can be executed setting OCR_TYPE
and then

make run

Note: to run on multiple hardware nodes on x86-mpi requires
specifying a "nodefile" with a list of nodes to run on

The directory has an example nodefile16 and a go.sh
script that invokes it.

Both of them will probably have to be patched to
correspond to the environment you are running on.
